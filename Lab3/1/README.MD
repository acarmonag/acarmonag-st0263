# LAB 3-1: Gesti贸n de Archivos en HDFS y S3

| Informaci贸n |  |
| --- | --- |
| Materia | T贸picos especiales en Telem谩tica |
| Curso | ST0263 |
| Estudiante | Antonio Carmona Gaviria (acarmonag@eafit.edu.co) |
| Profesor | Edwin Nelson Montoya Munera (emontoya@eafit.edu.co) |


## 1. Objetivo

El objetivo de este laboratorio es copiar todos los archivos disponibles en el repositorio [ Datasets](https://github.com/st0263eafit/st0263-232/tree/main/bigdata/datasets) a dos sistemas de almacenamiento distintos: HDFS, que se utiliza para almacenamiento temporal, y S3, empleado para almacenamiento permanente.

## 2. Aspectos Solucionados y No Solucionados

Se lograron los siguientes objetivos:

- Crear un bucket p煤blico en AWS S3.
- Gestionar archivos en HDFS a trav茅s de la terminal.
- Manejar archivos en HDFS mediante la interfaz de HUE.
- Administrar archivos en S3 utilizando HUE.

## 5. Ambiente de Ejecuci贸n

### Gu铆a de Uso

#### Parte 1: Creaci贸n de un Bucket P煤blico en AWS S3

1. **Acceso a AWS S3:** Ingresar a la consola de AWS, buscar el servicio S3 y seleccionar la opci贸n 'Crear bucket'.
2. **Configuraci贸n del Bucket:** Asignar un nombre 煤nico al bucket. En la secci贸n 'Object Ownership', activar 'ACLs enabled' y marcar la casilla 'Object writer'. En 'Block Public Access settings for this bucket', desactivar la opci贸n 'Block all public access' y aceptar las advertencias sobre la configuraci贸n de acceso p煤blico.
   
   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/1.png)
   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/2.png)
   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/3.png)

3. **Creaci贸n del Bucket:** Dejar las opciones restantes por defecto y finalizar la creaci贸n del bucket con el bot贸n correspondiente.
   
   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/4.png)
   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/5.png)


4. **Configuraci贸n de Permisos:** En el men煤 de S3, abrir el bucket creado y, en la secci贸n 'Permissions', editar 'Access control list (ACL)'. Activar las casillas 'List' y 'Read' para 'Everyone (public access)' y 'Authenticated users group'. Aceptar los t茅rminos y guardar los cambios.

   ![Untitled](https://github.com/acarmonag/acarmonag-st0263/blob/master/Lab3/1/IMGS/6.png)

5. **Carga de Archivos:** Ir al enlace [锔 airlines](https://github.com/st0263eafit/st0263-232/blob/main/bigdata/datasets/airlines.csv), descargar el archivo y cargarlo en el bucket.


6. **Verificaci贸n de Acceso P煤blico:** Copiar la URL del objeto en S3, eliminando la parte '/airlines.csv' del final, y verificar el acceso p煤blico en el navegador.

7. **Comandos CLI para AWS:** Se puede usar el comando `aws s3 ls s3://nombre-del-bucket` para listar los contenidos del bucket desde la CLI.

   ```bash
   aws s3 ls s3://datasetsspuertaf
   ```

#### Parte 2: Gesti贸n de Archivos en HDFS v铆a Terminal

1. **Preparaci贸n de Archivos:** Descargar y descomprimir 'datasets.zip'.
2. **Creaci贸n de Cl煤ster AWS EMR:** Seguir la gu铆a 'Creaci贸n de un Cl煤ster EMR' para configurar el cl煤ster.
3. **Conexi贸n SSH al Cl煤ster:** Usar SSH para conectarse al cl煤ster EMR.
4. **Creaci贸n de Directorios en HDFS:** Usar comandos para crear directorios '/user/hadoop/datasets' y '/user/hadoop/datasets/gutenberg-small' en HDFS.

   ```bash
   hdfs dfs -mkdir /user/hadoop/datasets
   hdfs dfs -mkdir /user/hadoop/datasets/gutenberg-small
   ```

5. **Transferencia de Archivos a HDFS:** Mover los archivos descomprimidos de 'gutenberg-small' al directorio creado en HDFS.

   ```bash
   hdfs dfs -put /ruta/local/gutenberg-small/*.txt /user/hadoop/datasets/gutenberg-small/
   ```

#### Parte 3: Gesti贸n de Archivos en HDFS v铆a HUE

1. **Acceso a HUE:** Ingresar a la consola AWS EMR, seleccionar el cl煤ster y acceder a HUE usando las credenciales apropiadas.
2. **Creaci贸n de Directorios en HDFS desde HUE:** Utilizar la interfaz de HUE para

 crear directorios necesarios en HDFS.
3. **Carga de Archivos desde HUE:** Subir archivos locales al directorio creado en HDFS utilizando las herramientas de HUE.

#### Parte 4: Gesti贸n de Archivos en S3 v铆a HUE

1. **Navegaci贸n en HUE hacia S3:** Dentro de la interfaz de HUE, seleccionar la secci贸n de S3.
2. **Selecci贸n de Bucket y Carga de Archivos:** Elegir el bucket creado y utilizar la opci贸n de carga de archivos para subir documentos desde la interfaz de HUE.

**Conclusi贸n:** La gu铆a proporciona instrucciones detalladas para la gesti贸n de archivos en HDFS y S3, abarcando tanto m茅todos de l铆nea de comandos como interfaces gr谩ficas como HUE, y la configuraci贸n de un bucket p煤blico en AWS S3.